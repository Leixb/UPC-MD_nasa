%! TEX root = **/010-main.tex
% vim: spell spelllang=en:

\section{Evaluation criteria of data mining models}%
\label{sec:eval-criteria}

% Description of the procedure followed in order to obtain a representative validation data set and
% description of the method that will be used to evaluate the different data mining models. 
% This includes description of parameters used in the evaluation (Cross-validation?
% K-fold cross-validation?  How many folders? Why that number?) 
% and discussion of the metric used for evaluation (accuracy,f1, etc).
% Which is the splitting procedure of data set into train and validation dataset? 
% Description of the procedure followed in order to obtain a representative validation data set.

To obtain a representative validation data set, we decided to split the dataset 70\%
for training and 30\% for validation and testing. We also checked that the target
column categories had their proportions respected. However, we didn't create training
and validation datasets as such, but for each algorithm we split the data using the same
procedures and seeds.

To optimize the parameters for the algorithms that required it we used k-fold cross 
validation. The value of k chosen for k-fold cross validation is 5. We selected it mainly
because of computational performance and execution time issues.

Regarding the metrics, we decided to use F-measure to asses the quality of our 
classifiers. We choose it mainly because our dataset is slightly unbalanced, with
a 30:70 split in our target column, and therefore F-measure provided 
clearer understanding of the performance and the behaviour of the algorithms.