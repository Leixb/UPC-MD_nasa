{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import plotting\n",
    "import numpy as np\n",
    "pandas.options.display.max_columns = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../kepler.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid</th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_teq_err1</th>\n",
       "      <th>koi_teq_err2</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_tce_delivname</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9.564000e+03</td>\n",
       "      <td>9564</td>\n",
       "      <td>2294</td>\n",
       "      <td>9564</td>\n",
       "      <td>9564</td>\n",
       "      <td>8054.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9.201000e+03</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.243000e+03</td>\n",
       "      <td>9.243000e+03</td>\n",
       "      <td>9.243000e+03</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9218.000000</td>\n",
       "      <td>9218</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9081.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9564</td>\n",
       "      <td>2294</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K07526.01</td>\n",
       "      <td>Kepler-880 b</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q1_q17_dr25_tce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5023</td>\n",
       "      <td>5068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4782.500000</td>\n",
       "      <td>7.690628e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.480829</td>\n",
       "      <td>0.188206</td>\n",
       "      <td>0.231598</td>\n",
       "      <td>0.194898</td>\n",
       "      <td>0.120033</td>\n",
       "      <td>75.671358</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>-0.002148</td>\n",
       "      <td>166.183251</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>0.735105</td>\n",
       "      <td>1.959861</td>\n",
       "      <td>-0.332557</td>\n",
       "      <td>5.621606</td>\n",
       "      <td>0.339942</td>\n",
       "      <td>-0.339942</td>\n",
       "      <td>2.379134e+04</td>\n",
       "      <td>123.197563</td>\n",
       "      <td>-123.197563</td>\n",
       "      <td>102.891778</td>\n",
       "      <td>17.657684</td>\n",
       "      <td>-33.023314</td>\n",
       "      <td>1085.385828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.745737e+03</td>\n",
       "      <td>3.750698e+03</td>\n",
       "      <td>-4.043522e+03</td>\n",
       "      <td>259.895001</td>\n",
       "      <td>1.243654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5706.823280</td>\n",
       "      <td>144.635554</td>\n",
       "      <td>-162.265059</td>\n",
       "      <td>4.310157</td>\n",
       "      <td>0.120738</td>\n",
       "      <td>-0.143161</td>\n",
       "      <td>1.728712</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>-0.394806</td>\n",
       "      <td>292.060163</td>\n",
       "      <td>43.810433</td>\n",
       "      <td>14.264606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2761.033321</td>\n",
       "      <td>2.653459e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476928</td>\n",
       "      <td>0.390897</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.396143</td>\n",
       "      <td>0.325018</td>\n",
       "      <td>1334.744046</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>67.918960</td>\n",
       "      <td>0.023097</td>\n",
       "      <td>0.023097</td>\n",
       "      <td>3.348832</td>\n",
       "      <td>9.421653</td>\n",
       "      <td>1.249828</td>\n",
       "      <td>6.471554</td>\n",
       "      <td>0.669823</td>\n",
       "      <td>0.669823</td>\n",
       "      <td>8.224268e+04</td>\n",
       "      <td>4112.615230</td>\n",
       "      <td>4112.615230</td>\n",
       "      <td>3077.639126</td>\n",
       "      <td>391.138501</td>\n",
       "      <td>1193.519910</td>\n",
       "      <td>856.351161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.592047e+05</td>\n",
       "      <td>5.504421e+04</td>\n",
       "      <td>8.838831e+04</td>\n",
       "      <td>795.806615</td>\n",
       "      <td>0.664573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>796.857947</td>\n",
       "      <td>47.052305</td>\n",
       "      <td>72.746348</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>0.132837</td>\n",
       "      <td>0.085477</td>\n",
       "      <td>6.127185</td>\n",
       "      <td>0.930870</td>\n",
       "      <td>2.168213</td>\n",
       "      <td>4.766657</td>\n",
       "      <td>3.601243</td>\n",
       "      <td>1.385448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.574500e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.172500</td>\n",
       "      <td>120.515914</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.569000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-59.320000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.200000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-388600.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-77180.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.600031e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2661.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1762.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.207000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-116.137000</td>\n",
       "      <td>279.852720</td>\n",
       "      <td>36.577381</td>\n",
       "      <td>6.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2391.750000</td>\n",
       "      <td>5.556034e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.733684</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>132.761718</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>-0.010500</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>2.437750</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>1.599000e+02</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>-49.500000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>-1.940000</td>\n",
       "      <td>539.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.015000e+01</td>\n",
       "      <td>9.190000e+00</td>\n",
       "      <td>-2.873100e+02</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5310.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>-198.000000</td>\n",
       "      <td>4.218000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>-0.196000</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>288.660770</td>\n",
       "      <td>40.777173</td>\n",
       "      <td>13.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4782.500000</td>\n",
       "      <td>7.906892e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.752831</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>137.224595</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>-0.004130</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>-0.207000</td>\n",
       "      <td>3.792600</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>-0.142000</td>\n",
       "      <td>4.211000e+02</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>-20.750000</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.416000e+02</td>\n",
       "      <td>7.283000e+01</td>\n",
       "      <td>-4.026000e+01</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5767.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>-160.000000</td>\n",
       "      <td>4.438000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.128000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>-0.111000</td>\n",
       "      <td>292.261125</td>\n",
       "      <td>43.677504</td>\n",
       "      <td>14.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7173.250000</td>\n",
       "      <td>9.873066e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.715178</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>170.694603</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>-0.001240</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>-0.046000</td>\n",
       "      <td>6.276500</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>-0.050800</td>\n",
       "      <td>1.473400e+03</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>-9.600000</td>\n",
       "      <td>14.930000</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>-0.140000</td>\n",
       "      <td>1379.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.702900e+02</td>\n",
       "      <td>5.194150e+02</td>\n",
       "      <td>-5.160000e+00</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6112.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>4.543000</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>-0.088000</td>\n",
       "      <td>1.345000</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>-0.069000</td>\n",
       "      <td>295.859160</td>\n",
       "      <td>46.714611</td>\n",
       "      <td>15.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9564.000000</td>\n",
       "      <td>1.293514e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>129995.778400</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1472.522306</td>\n",
       "      <td>0.569000</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>100.806000</td>\n",
       "      <td>85.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.540000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.541400e+06</td>\n",
       "      <td>388600.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200346.000000</td>\n",
       "      <td>21640.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14667.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.094755e+07</td>\n",
       "      <td>3.617133e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9054.700000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15896.000000</td>\n",
       "      <td>676.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.364000</td>\n",
       "      <td>1.472000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>229.908000</td>\n",
       "      <td>33.091000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>301.720760</td>\n",
       "      <td>52.336010</td>\n",
       "      <td>20.003000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rowid         kepid kepoi_name   kepler_name koi_disposition  \\\n",
       "count   9564.000000  9.564000e+03       9564          2294            9564   \n",
       "unique          NaN           NaN       9564          2294               3   \n",
       "top             NaN           NaN  K07526.01  Kepler-880 b  FALSE POSITIVE   \n",
       "freq            NaN           NaN          1             1            5023   \n",
       "mean    4782.500000  7.690628e+06        NaN           NaN             NaN   \n",
       "std     2761.033321  2.653459e+06        NaN           NaN             NaN   \n",
       "min        1.000000  7.574500e+05        NaN           NaN             NaN   \n",
       "25%     2391.750000  5.556034e+06        NaN           NaN             NaN   \n",
       "50%     4782.500000  7.906892e+06        NaN           NaN             NaN   \n",
       "75%     7173.250000  9.873066e+06        NaN           NaN             NaN   \n",
       "max     9564.000000  1.293514e+07        NaN           NaN             NaN   \n",
       "\n",
       "       koi_pdisposition    koi_score  koi_fpflag_nt  koi_fpflag_ss  \\\n",
       "count              9564  8054.000000    9564.000000    9564.000000   \n",
       "unique                2          NaN            NaN            NaN   \n",
       "top      FALSE POSITIVE          NaN            NaN            NaN   \n",
       "freq               5068          NaN            NaN            NaN   \n",
       "mean                NaN     0.480829       0.188206       0.231598   \n",
       "std                 NaN     0.476928       0.390897       0.421875   \n",
       "min                 NaN     0.000000       0.000000       0.000000   \n",
       "25%                 NaN     0.000000       0.000000       0.000000   \n",
       "50%                 NaN     0.334000       0.000000       0.000000   \n",
       "75%                 NaN     0.998000       0.000000       0.000000   \n",
       "max                 NaN     1.000000       1.000000       1.000000   \n",
       "\n",
       "        koi_fpflag_co  koi_fpflag_ec     koi_period  koi_period_err1  \\\n",
       "count     9564.000000    9564.000000    9564.000000      9110.000000   \n",
       "unique            NaN            NaN            NaN              NaN   \n",
       "top               NaN            NaN            NaN              NaN   \n",
       "freq              NaN            NaN            NaN              NaN   \n",
       "mean         0.194898       0.120033      75.671358         0.002148   \n",
       "std          0.396143       0.325018    1334.744046         0.008236   \n",
       "min          0.000000       0.000000       0.241843         0.000000   \n",
       "25%          0.000000       0.000000       2.733684         0.000005   \n",
       "50%          0.000000       0.000000       9.752831         0.000035   \n",
       "75%          0.000000       0.000000      40.715178         0.000276   \n",
       "max          1.000000       1.000000  129995.778400         0.172500   \n",
       "\n",
       "        koi_period_err2  koi_time0bk  koi_time0bk_err1  koi_time0bk_err2  \\\n",
       "count       9110.000000  9564.000000       9110.000000       9110.000000   \n",
       "unique              NaN          NaN               NaN               NaN   \n",
       "top                 NaN          NaN               NaN               NaN   \n",
       "freq                NaN          NaN               NaN               NaN   \n",
       "mean          -0.002148   166.183251          0.009933         -0.009933   \n",
       "std            0.008236    67.918960          0.023097          0.023097   \n",
       "min           -0.172500   120.515914          0.000009         -0.569000   \n",
       "25%           -0.000276   132.761718          0.001240         -0.010500   \n",
       "50%           -0.000035   137.224595          0.004130         -0.004130   \n",
       "75%           -0.000005   170.694603          0.010500         -0.001240   \n",
       "max            0.000000  1472.522306          0.569000         -0.000009   \n",
       "\n",
       "         koi_impact  koi_impact_err1  koi_impact_err2  koi_duration  \\\n",
       "count   9201.000000      9110.000000      9110.000000   9564.000000   \n",
       "unique          NaN              NaN              NaN           NaN   \n",
       "top             NaN              NaN              NaN           NaN   \n",
       "freq            NaN              NaN              NaN           NaN   \n",
       "mean       0.735105         1.959861        -0.332557      5.621606   \n",
       "std        3.348832         9.421653         1.249828      6.471554   \n",
       "min        0.000000         0.000000       -59.320000      0.052000   \n",
       "25%        0.197000         0.040000        -0.445000      2.437750   \n",
       "50%        0.537000         0.193000        -0.207000      3.792600   \n",
       "75%        0.889000         0.378000        -0.046000      6.276500   \n",
       "max      100.806000        85.540000         0.000000    138.540000   \n",
       "\n",
       "        koi_duration_err1  koi_duration_err2     koi_depth  koi_depth_err1  \\\n",
       "count         9110.000000        9110.000000  9.201000e+03     9110.000000   \n",
       "unique                NaN                NaN           NaN             NaN   \n",
       "top                   NaN                NaN           NaN             NaN   \n",
       "freq                  NaN                NaN           NaN             NaN   \n",
       "mean             0.339942          -0.339942  2.379134e+04      123.197563   \n",
       "std              0.669823           0.669823  8.224268e+04     4112.615230   \n",
       "min              0.000000         -20.200000  0.000000e+00        0.000000   \n",
       "25%              0.050800          -0.350000  1.599000e+02        9.600000   \n",
       "50%              0.142000          -0.142000  4.211000e+02       20.750000   \n",
       "75%              0.350000          -0.050800  1.473400e+03       49.500000   \n",
       "max             20.200000           0.000000  1.541400e+06   388600.000000   \n",
       "\n",
       "        koi_depth_err2       koi_prad  koi_prad_err1  koi_prad_err2  \\\n",
       "count      9110.000000    9201.000000    9201.000000    9201.000000   \n",
       "unique             NaN            NaN            NaN            NaN   \n",
       "top                NaN            NaN            NaN            NaN   \n",
       "freq               NaN            NaN            NaN            NaN   \n",
       "mean       -123.197563     102.891778      17.657684     -33.023314   \n",
       "std        4112.615230    3077.639126     391.138501    1193.519910   \n",
       "min     -388600.000000       0.080000       0.000000  -77180.000000   \n",
       "25%         -49.500000       1.400000       0.230000      -1.940000   \n",
       "50%         -20.750000       2.390000       0.520000      -0.300000   \n",
       "75%          -9.600000      14.930000       2.320000      -0.140000   \n",
       "max           0.000000  200346.000000   21640.000000       0.000000   \n",
       "\n",
       "             koi_teq  koi_teq_err1  koi_teq_err2     koi_insol  \\\n",
       "count    9201.000000           0.0           0.0  9.243000e+03   \n",
       "unique           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN   \n",
       "mean     1085.385828           NaN           NaN  7.745737e+03   \n",
       "std       856.351161           NaN           NaN  1.592047e+05   \n",
       "min        25.000000           NaN           NaN  0.000000e+00   \n",
       "25%       539.000000           NaN           NaN  2.015000e+01   \n",
       "50%       878.000000           NaN           NaN  1.416000e+02   \n",
       "75%      1379.000000           NaN           NaN  8.702900e+02   \n",
       "max     14667.000000           NaN           NaN  1.094755e+07   \n",
       "\n",
       "        koi_insol_err1  koi_insol_err2  koi_model_snr  koi_tce_plnt_num  \\\n",
       "count     9.243000e+03    9.243000e+03    9201.000000       9218.000000   \n",
       "unique             NaN             NaN            NaN               NaN   \n",
       "top                NaN             NaN            NaN               NaN   \n",
       "freq               NaN             NaN            NaN               NaN   \n",
       "mean      3.750698e+03   -4.043522e+03     259.895001          1.243654   \n",
       "std       5.504421e+04    8.838831e+04     795.806615          0.664573   \n",
       "min       0.000000e+00   -5.600031e+06       0.000000          1.000000   \n",
       "25%       9.190000e+00   -2.873100e+02      12.000000          1.000000   \n",
       "50%       7.283000e+01   -4.026000e+01      23.000000          1.000000   \n",
       "75%       5.194150e+02   -5.160000e+00      78.000000          1.000000   \n",
       "max       3.617133e+06    0.000000e+00    9054.700000          8.000000   \n",
       "\n",
       "       koi_tce_delivname     koi_steff  koi_steff_err1  koi_steff_err2  \\\n",
       "count               9218   9201.000000     9096.000000     9081.000000   \n",
       "unique                 3           NaN             NaN             NaN   \n",
       "top      q1_q17_dr25_tce           NaN             NaN             NaN   \n",
       "freq                8054           NaN             NaN             NaN   \n",
       "mean                 NaN   5706.823280      144.635554     -162.265059   \n",
       "std                  NaN    796.857947       47.052305       72.746348   \n",
       "min                  NaN   2661.000000        0.000000    -1762.000000   \n",
       "25%                  NaN   5310.000000      106.000000     -198.000000   \n",
       "50%                  NaN   5767.000000      157.000000     -160.000000   \n",
       "75%                  NaN   6112.000000      174.000000     -114.000000   \n",
       "max                  NaN  15896.000000      676.000000        0.000000   \n",
       "\n",
       "          koi_slogg  koi_slogg_err1  koi_slogg_err2     koi_srad  \\\n",
       "count   9201.000000     9096.000000     9096.000000  9201.000000   \n",
       "unique          NaN             NaN             NaN          NaN   \n",
       "top             NaN             NaN             NaN          NaN   \n",
       "freq            NaN             NaN             NaN          NaN   \n",
       "mean       4.310157        0.120738       -0.143161     1.728712   \n",
       "std        0.432606        0.132837        0.085477     6.127185   \n",
       "min        0.047000        0.000000       -1.207000     0.109000   \n",
       "25%        4.218000        0.042000       -0.196000     0.829000   \n",
       "50%        4.438000        0.070000       -0.128000     1.000000   \n",
       "75%        4.543000        0.149000       -0.088000     1.345000   \n",
       "max        5.364000        1.472000        0.000000   229.908000   \n",
       "\n",
       "        koi_srad_err1  koi_srad_err2           ra          dec   koi_kepmag  \n",
       "count     9096.000000    9096.000000  9564.000000  9564.000000  9563.000000  \n",
       "unique            NaN            NaN          NaN          NaN          NaN  \n",
       "top               NaN            NaN          NaN          NaN          NaN  \n",
       "freq              NaN            NaN          NaN          NaN          NaN  \n",
       "mean         0.362292      -0.394806   292.060163    43.810433    14.264606  \n",
       "std          0.930870       2.168213     4.766657     3.601243     1.385448  \n",
       "min          0.000000    -116.137000   279.852720    36.577381     6.966000  \n",
       "25%          0.129000      -0.250000   288.660770    40.777173    13.440000  \n",
       "50%          0.251000      -0.111000   292.261125    43.677504    14.520000  \n",
       "75%          0.364000      -0.069000   295.859160    46.714611    15.322000  \n",
       "max         33.091000       0.000000   301.720760    52.336010    20.003000  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rowid                   0\n",
       "kepid                   0\n",
       "kepoi_name              0\n",
       "kepler_name          7270\n",
       "koi_disposition         0\n",
       "koi_pdisposition        0\n",
       "koi_score            1510\n",
       "koi_fpflag_nt           0\n",
       "koi_fpflag_ss           0\n",
       "koi_fpflag_co           0\n",
       "koi_fpflag_ec           0\n",
       "koi_period              0\n",
       "koi_period_err1       454\n",
       "koi_period_err2       454\n",
       "koi_time0bk             0\n",
       "koi_time0bk_err1      454\n",
       "koi_time0bk_err2      454\n",
       "koi_impact            363\n",
       "koi_impact_err1       454\n",
       "koi_impact_err2       454\n",
       "koi_duration            0\n",
       "koi_duration_err1     454\n",
       "koi_duration_err2     454\n",
       "koi_depth             363\n",
       "koi_depth_err1        454\n",
       "koi_depth_err2        454\n",
       "koi_prad              363\n",
       "koi_prad_err1         363\n",
       "koi_prad_err2         363\n",
       "koi_teq               363\n",
       "koi_teq_err1         9564\n",
       "koi_teq_err2         9564\n",
       "koi_insol             321\n",
       "koi_insol_err1        321\n",
       "koi_insol_err2        321\n",
       "koi_model_snr         363\n",
       "koi_tce_plnt_num      346\n",
       "koi_tce_delivname     346\n",
       "koi_steff             363\n",
       "koi_steff_err1        468\n",
       "koi_steff_err2        483\n",
       "koi_slogg             363\n",
       "koi_slogg_err1        468\n",
       "koi_slogg_err2        468\n",
       "koi_srad              363\n",
       "koi_srad_err1         468\n",
       "koi_srad_err2         468\n",
       "ra                      0\n",
       "dec                     0\n",
       "koi_kepmag              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "notActive = ['rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_pdisposition', 'koi_teq_err1', 'koi_teq_err2', 'koi_tce_delivname', 'koi_score']\n",
    "df = df.drop(notActive, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.koi_disposition == 'CANDIDATE'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.replace({'koi_disposition': {'CONFIRMED': 1, 'FALSE POSITIVE': 0}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA TRANSFORMATION: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.775000e-05</td>\n",
       "      <td>-2.775000e-05</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>-0.002160</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>0.08190</td>\n",
       "      <td>-0.08190</td>\n",
       "      <td>615.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>793.0</td>\n",
       "      <td>93.59</td>\n",
       "      <td>29.45</td>\n",
       "      <td>-16.65</td>\n",
       "      <td>35.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>874.8</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>443.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.494000e-05</td>\n",
       "      <td>-1.494000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.969</td>\n",
       "      <td>5.126</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.92</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>638.0</td>\n",
       "      <td>39.30</td>\n",
       "      <td>31.04</td>\n",
       "      <td>-10.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>33.46</td>\n",
       "      <td>8.50</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>891.96</td>\n",
       "      <td>668.95</td>\n",
       "      <td>-230.35</td>\n",
       "      <td>505.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.761000e-06</td>\n",
       "      <td>-3.761000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>603.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-16.9</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>926.16</td>\n",
       "      <td>874.33</td>\n",
       "      <td>-314.24</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0                1              0              0              0   \n",
       "1                1              0              0              0   \n",
       "2                0              0              1              0   \n",
       "3                0              0              1              0   \n",
       "4                1              0              0              0   \n",
       "\n",
       "   koi_fpflag_ec  koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0              0    9.488036     2.775000e-05    -2.775000e-05   170.538750   \n",
       "1              0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "2              0   19.899140     1.494000e-05    -1.494000e-05   175.850252   \n",
       "3              0    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "4              0    2.525592     3.761000e-06    -3.761000e-06   171.595550   \n",
       "\n",
       "   koi_time0bk_err1  koi_time0bk_err2  koi_impact  koi_impact_err1  \\\n",
       "0          0.002160         -0.002160       0.146            0.318   \n",
       "1          0.003520         -0.003520       0.586            0.059   \n",
       "2          0.000581         -0.000581       0.969            5.126   \n",
       "3          0.000115         -0.000115       1.276            0.115   \n",
       "4          0.001130         -0.001130       0.701            0.235   \n",
       "\n",
       "   koi_impact_err2  koi_duration  koi_duration_err1  koi_duration_err2  \\\n",
       "0           -0.146       2.95750            0.08190           -0.08190   \n",
       "1           -0.443       4.50700            0.11600           -0.11600   \n",
       "2           -0.077       1.78220            0.03410           -0.03410   \n",
       "3           -0.092       2.40641            0.00537           -0.00537   \n",
       "4           -0.478       1.65450            0.04200           -0.04200   \n",
       "\n",
       "   koi_depth  koi_depth_err1  koi_depth_err2  koi_prad  koi_prad_err1  \\\n",
       "0      615.8            19.5           -19.5      2.26           0.26   \n",
       "1      874.8            35.5           -35.5      2.83           0.32   \n",
       "2    10829.0           171.0          -171.0     14.60           3.92   \n",
       "3     8079.2            12.8           -12.8     33.46           8.50   \n",
       "4      603.3            16.9           -16.9      2.75           0.88   \n",
       "\n",
       "   koi_prad_err2  koi_teq  koi_insol  koi_insol_err1  koi_insol_err2  \\\n",
       "0          -0.15    793.0      93.59           29.45          -16.65   \n",
       "1          -0.19    443.0       9.11            2.87           -1.62   \n",
       "2          -1.31    638.0      39.30           31.04          -10.49   \n",
       "3          -2.83   1395.0     891.96          668.95         -230.35   \n",
       "4          -0.35   1406.0     926.16          874.33         -314.24   \n",
       "\n",
       "   koi_model_snr  koi_tce_plnt_num  koi_steff  koi_steff_err1  koi_steff_err2  \\\n",
       "0           35.8               1.0     5455.0            81.0           -81.0   \n",
       "1           25.8               2.0     5455.0            81.0           -81.0   \n",
       "2           76.3               1.0     5853.0           158.0          -176.0   \n",
       "3          505.6               1.0     5805.0           157.0          -174.0   \n",
       "4           40.9               1.0     6031.0           169.0          -211.0   \n",
       "\n",
       "   koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  \\\n",
       "0      4.467           0.064          -0.096     0.927          0.105   \n",
       "1      4.467           0.064          -0.096     0.927          0.105   \n",
       "2      4.544           0.044          -0.176     0.868          0.233   \n",
       "3      4.564           0.053          -0.168     0.791          0.201   \n",
       "4      4.438           0.070          -0.210     1.046          0.334   \n",
       "\n",
       "   koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0         -0.061  291.93423  48.141651      15.347  \n",
       "1         -0.061  291.93423  48.141651      15.347  \n",
       "2         -0.078  297.00482  48.134129      15.436  \n",
       "3         -0.067  285.53461  48.285210      15.597  \n",
       "4         -0.133  288.75488  48.226200      15.509  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kepler = df.values[:,1:]\n",
    "y_kepler = df.values[:,0]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8489769983479476"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.neighbors as nb\n",
    "import numpy as np\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1) \n",
    "\n",
    "cv_scores = cross_val_score(nb.KNeighborsClassifier(), X=X_kepler,y=y_kepler, cv=cv, scoring='accuracy')  \n",
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params= {'n_neighbors': 9, 'weights': 'distance'} Accuracy= 0.8549753963914708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_neighbors':list(range(1,20,2)), 'weights':('distance','uniform')}\n",
    "knc = nb.KNeighborsClassifier()\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1) \n",
    "clf = GridSearchCV(knc, param_grid=params,cv=cv,n_jobs=-1,iid='False')  # If cv is integer, by default is Stratifyed \n",
    "clf.fit(X_kepler, y_kepler)\n",
    "print(\"Best Params=\",clf.best_params_, \"Accuracy=\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 0.4306998142865243 min 0.0 max 1.0\n",
      "std: 0.45755025653239634 min 0.0 max 1.0\n",
      "std: 0.4357397508893314 min 0.0 max 1.0\n",
      "std: 0.3637218821376634 min 0.0 max 1.0\n",
      "std: 121.07412209217257 min 0.241842544 max 1071.232624\n",
      "std: 0.008273456437910182 min 1.1000000000000001e-08 max 0.1725\n",
      "std: 0.008273456437910182 min -0.1725 max -1.1000000000000001e-08\n",
      "std: 65.64187929488227 min 120.5159138 max 1472.522306\n",
      "std: 0.02101941335075974 min 8.7e-06 max 0.569\n",
      "std: 0.02101941335075974 min -0.569 max -8.7e-06\n",
      "std: 3.5923635061593533 min 0.0 max 100.806\n",
      "std: 9.39910512747779 min 0.0 max 85.54\n",
      "std: 1.1887456818793 min -37.53 max 0.0\n"
     ]
    }
   ],
   "source": [
    "# Poor score. What could happen? \n",
    "# Remeber that all columns should be in the same range for KNN!!\n",
    "# Could be that each colum is in a different range?\n",
    "\n",
    "for i in range(13):\n",
    "    print('std:',X_kepler[:,i].std(),'min',X_kepler[:,i].min(),'max',X_kepler[:,i].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 0.9999999999999999 min -0.5712472518709594 max 1.7505554674001178\n",
      "std: 0.9999999999999998 min -0.6521405955174382 max 1.5334116705410032\n",
      "std: 1.0000000000000002 min -0.5847160707091617 max 1.7102317690484707\n",
      "std: 1.0 min -0.43141849703617785 max 2.31793492135814\n",
      "std: 0.9999999999999999 min -0.48379368514605353 max 8.361951078054997\n",
      "std: 1.0 min -0.2566379481954387 max 20.593171353945795\n",
      "std: 1.0 min -20.593171353945795 max 0.2566379481954387\n",
      "std: 0.9999999999999999 min -0.6758191875052232 max 19.920885335934717\n",
      "std: 1.0 min -0.4235329311917715 max 26.646266330329194\n",
      "std: 1.0 min -26.646266330329194 max 0.4235329311917715\n",
      "std: 1.0 min -0.22179641091916275 max 27.839395010038434\n",
      "std: 1.0 min -0.22130150392953485 max 8.879564891311466\n",
      "std: 1.0 min -31.297422799575596 max 0.2736698000361578\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# One way is to standarize all data mean 0, std 1\n",
    "scaler = preprocessing.StandardScaler().fit(X_kepler)\n",
    "X2=scaler.transform(X_kepler)\n",
    "\n",
    "for i in range(13):\n",
    "    print('std:',X2[:,i].std(),'min',X2[:,i].min(),'max',X2[:,i].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params= {'n_neighbors': 3, 'weights': 'distance'} Accuracy= 0.9766265718972116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Let's repeat the 10-fold Cross-validation with new data X2\n",
    "knc = nb.KNeighborsClassifier()\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1) \n",
    "clf = GridSearchCV(knc, param_grid=params,cv=cv,n_jobs=-1,iid='False')  # If cv is integer, by default is Stratifyed \n",
    "clf.fit(X2, y_kepler)\n",
    "print(\"Best Params=\",clf.best_params_, \"Accuracy=\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION: Effect of irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n",
      "<ipython-input-152-1a7f9371694b>:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,1)\n",
      "<ipython-input-152-1a7f9371694b>:9: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.subplot(5,4,2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAACFCAYAAADLqTRIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQgElEQVR4nO3dfbAddX3H8feHZyggCaQhTQI30AimVSFeSaYUqqDhQSRYUcIgRE2boqEDAx0J4JSMaAfqCEJVMJS0QJGEJyGlKA0QUGdKQhIiTzEkPJVAIMhTUCgY/faP/d1kudyHPfeePeeePZ/XzJm7+zu7537PzTffs/v77f6OIgIzsyrbqtkBmJmVzYXOzCrPhc7MKs+Fzswqz4XOzCpvm2YHUIY99tgjOjo6mh2GdbN8+fJfR8SIZsdRD86xoaev/Kpkoevo6GDZsmXNDsO6kfRMs2OoF+fY0NNXfvnU1cwqz4XOzCrPhc7MKq+SfXTNtm72zzcvL3jqIgB2GHbmu7aZdcVhDY3J2ks+B2FLHnY5a8HtjQyn6XxEZ9aGvn/qPc0OoaFc6Mys8lzozKzyXOjMrPJc6Mys8lzozKzyXOisJUkaK2mxpMckPSrp9NQ+XNIiSWvSz2GpXZIuk7RW0kOSJuZea3rafo2k6c16T1YeFzprVZuAsyJiAjAZmCVpAjAbuDsixgN3p3WAo4Dx6TETuByywgicD0wCDgLO7yqOVh0udNaSImJ9RKxIy28Aq4DRwFTg6rTZ1cBxaXkqcE1k7gd2kzQKOAJYFBGvRMSrwCLgyMa9E2sEFzpreZI6gAOBJcDIiFifnnoBGJmWRwPP5nZbl9p6a7cKcaGzliZpZ+Bm4IyI2Jh/LrKvuKvb19xJmilpmaRlL730Ur1e1hrAhc5alqRtyYrcdRFxS2p+MZ2Skn5uSO3PAWNzu49Jbb21v0dEzI2IzojoHDGiEvOHtg0XOmtJkgRcBayKiItzTy0EukZOpwO35dpPSaOvk4HX0ynuncAUScPSIMSU1GYVUnqhk7S1pAcl3Z7Wx0lakob5F0jaLrVvn9bXpuc7cq9xTmpfLemIsmO2lnAwcDJwmKSV6XE0cCHwSUlrgE+kdYA7gCeBtcCVwFcBIuIV4ALggfT4RmqzCmnENE2nk42I7ZrWLwIuiYj5kq4AZpAN9c8AXo2IP5U0LW13QrpkYBrwZ8CfAHdJen9E/L4BsdsQFRG/ANTL04f3sH0As3p5rXnAvPpFZ0NNqUd0ksYAnwL+Na0LOAy4KW3Sffi/67KAm4DD0/ZTgfkR8XZEPEX2iXxQmXGbWbUUKnSSPjjA1/8u8DXgD2l9d+C1iNiU1vND+ZuH+dPzr6ftCw3/e0SsdQ0iv8wKKXpE9wNJSyV9VdL7iuwg6RhgQ0QsH3h4xXlErKXVnF9mtShU6CLiEOAksmH45ZJ+JOmT/ex2MHCspKeB+WSnrJeSXZHe1TeYH8rfPMyfnn8f8DI1DP9baxpgfpkVVriPLiLWAF8Hzgb+CrhM0q8k/XUv258TEWMiooNsMOGeiDgJWAwcnzbrPvzfdVnA8Wn7SO3T0qjsOLJ7FZfW8B6tBdSaX2a1KNpH9yFJl5CNnh4GfDoiPpCWL6nxd54NnClpLVkf3FWp/Spg99R+Julm7Ih4FLgBeAz4KTDLI67VUuf8MnuPopeX/AvZyOm5EfFWV2NEPC/p6/3tHBH3Avem5SfpYdQ0Iv4P+Fwv+38L+FbBWK31DCq/zPpTtNB9Cnir60hK0lbADhHxZkRcW1p01i6cX1aqon10dwE75tZ3Sm1m9eD8slIVLXQ7RMRvulbS8k7lhGRtyPllpSpa6H7bberpjwBv9bG9WS2cX1aqon10ZwA3Snqe7P7CPYETygrK2s4ZOL+sRIUKXUQ8IGl/YL/UtDoifldeWNZOnF9WtlpmL/ko0JH2mSiJiLimlKisHTm/rDSFCp2ka4F9gZVA18W6ATgRbdCcX1a2okd0ncCEdEuWWb05v6xURUddHyHrIDYrg/PLSlX0iG4P4DFJS4G3uxoj4thSorJ24/yyUhUtdHPKDMLa3pxmB2DVVvTykvsk7Q2Mj4i7JO0EbF1uaNYunF9WtqLTNP0t2fc4/DA1jQZuLSkmazPOLytb0cGIWWQzBm+EzZMk/nFZQVnbcX5ZqYoWurcj4p2ulTTVuS8FsHpxflmpiha6+ySdC+yY5vK/EfjP8sKyNuP8slIVLXSzgZeAh4G/I/vWc8/8avXi/LJSFR11/QNwZXqY1ZXzq7n2XLySFz5+QLPDKFXRe12fooc+k4jYp+4RWdtxflnZarnXtcsOZF9iM7z+4Vibcn5ZqYp+gfXLucdzEfFdsi80MRu0geaXpHmSNkh6JNc2XNIiSWvSz2GpXZIuk7RW0kPdZjSenrZfI2l6T7/LWlvRU9eJudWtyD6Ba5nLzqxXg8ivfwe+x7unc5oN3B0RF0qandbPBo4i+/Lz8cAk4HJgkqThwPnpdwawXNLCiHh1UG/KhpSixeo7ueVNwNPA5+sejbWrAeVXRPxMUke35qnAx9Ly1WTfJ3x2ar8mTQV1v6TdJI1K2y6KiFcAJC0CjgSuH9hbsaGo6Kjrx8sOxNpXnfNrZESsT8svACPT8mjg2dx261Jbb+1WIUVPXc/s6/mIuLiHfcaSnVKMJDslmBsRl6ZThQVk02Y/DXw+Il6VJOBS4GjgTeCLEbEivdZ0tlxX9c2IuLpI3NYaBpJfRURESKrbHRaSZgIzAfbaa696vaw1QNELhjuBr7DlE/BUYCKwS3r0ZBNwVkRMACYDsyRNYEsfynjg7rQO7+5DmUnWh0KuD2UScBBwflcHs1XGQPKrNy+mU1LSzw2p/TlgbG67Mamtt/b3iIi5EdEZEZ0jRoyoMSxrpqJ9dGOAiRHxBoCkOcB/RcQXetshnT6sT8tvSFpFlsTuQ7Huas6vPiwEpgMXpp+35dpPkzSf7EPz9YhYL+lO4J9yH55TgHMG/E5sSCpa6EYC7+TW32FL30e/UofxgcASSupD8WlFSxtQfkm6nuyDcA9J68iO/C8EbpA0A3iGLYMad5B1i6wl6xr5EkBEvCLpAuCBtN03uj5UrTqKFrprgKWSfpzWjyM7GuuXpJ2Bm4EzImJj1hWXqWcfSkTMBeYCdHZ2euaL1jKg/IqIE3t56vAetg2y6aB6ep15wLxCkVpLKjrq+i1JPwEOSU1fiogH+9tP0rZkRe66iLglNb8oaVQ6bSjah/Kxbu33FonbWsNA88usqKKDEQA7ARsj4lJgnaRxfW2cRlGvAlZ1GzXr6kOB9/ahnJKuYJ9M6kMB7gSmSBqW+lGmpDarlpryy6wWRS8v6bpyfD/g34Btgf8gmxW2NwcDJwMPS1qZ2s7FfSjWzQDzy6ywon10nyEbTFgBEBHPS+pz2D8ifgGol6fdh2J5NeeXWS2Knrq+kwpRAEj6o/JCsjbk/LJSFS10N0j6IbBb+samu/AkiVY/zi8rVb+nrmlQYQGwP9m3NO0H/GNELCo5NmsDzi9rhH4LXbrW7Y6I+CDg5LO6cn5ZIxQ9dV0h6aOlRmLtzPllpSo66joJ+IKkp4Hfko2mRkR8qKzArK04v6xUfRY6SXtFxP8CRzQoHmsjzq/m23PxymaH0BD9HdHdSjarxDOSbo6IzzYgJmsft+L8sgbor48uf8Gvv3rO6s35ZQ3RX6GLXpbN6sH5ZQ3R36nrhyVtJPvk3TEtw5bO4l1Ljc6qzvllDdFnoYuIrRsViLUf55c1Si3TNJmZtSQXOjOrPBc6M6s8FzozqzwXOjOrPBc6M6s8Fzozq/w9ry50ZlZ5LnRmVnkudGZWeS50ZlZ5LnRmbeiCE4ZXfgAiz4XOzCqvZQqdpCMlrZa0VtLsZsdj1VLl/BqzwzHNDqHpWqLQSdoa+D5wFDABOFHShOZGZVXh/MrMmTOn2SGUpui3gDXbQcDaiHgSQNJ8YCrwWFOjsqqofH698YFOAHZZtYxvn/rNHrcZ8cKhgyp2Q7lQKmLoz2At6XjgyIj4m7R+MjApIk7LbTMTmJlW9wNWNzzQnu0B/LrZQZSs6HvcOyJGlB1MrYrkV2qvNceG0r/9UImlzDh6za9WOaLrV0TMBeY2O47uJC2LiM5mx1GmdniPUHuODaW/y1CJpVlxtEQfHfAcMDa3Pia1mdWD86viWqXQPQCMlzRO0nbANGBhk2Oy6nB+VVxLnLpGxCZJpwF3AlsD8yLi0SaHVdSQO50uQUu/xxLzayj9XYZKLE2JoyUGI8zMBqNVTl3NzAbMhc7MKs+FrkRVvq0IQNI8SRskPdLsWBpB0rcl/UrSQ5J+LGm31N4h6S1JK9Pjitw+H5H0cMqByyQptQ+XtEjSmvRzWGpX2m5t+j0TBxlz3XNQ0lhJiyU9JulRSaen9jmSnsv9HY7O7XNOimG1pCP6iy8NDC1J7QvSINHARYQfJTzIOrWfAPYBtgN+CUxodlx1fo+HAhOBR5odS4Pe7xRgm7R8EXBRWu7o7W8ALAUmAwJ+AhyV2v8ZmJ2WZ+de6+i0ndJ+SwYRbyk5CIwCJqblXYDHyW6dmwP8Qw/bT0i/e3tgXIpp677iA24ApqXlK4CvDCZmH9GVZ/NtRRHxDtB1W1FlRMTPgFeaHUejRMR/R8SmtHo/2fV2vZI0Ctg1Iu6P7H/sNcBx6empwNVp+epu7ddE5n5gt/Q6A1FKDkbE+ohYkZbfAFYBo/vYZSowPyLejoingLUpth7jS0e9hwE3pf3zf58BcaErz2jg2dz6OvpOBmstXyY78uoyTtKDku6TdEhqG032794lnwMjI2J9Wn4BGJnbp155U3oOSuoADgSWpKbT0in3vK7T8T7i6K19d+C13IfKoON2oTPLkXSXpEd6eEzNbXMesAm4LjWtB/aKiAOBM4EfSdq16O9MR3std52XpJ2Bm4EzImIjcDmwL3AA2d/kO82L7t1a4oLhFuXbilpQRHyir+clfRE4Bjg8FSgi4m3g7bS8XNITwPvJ/r3zp7f5HHhR0qiIWJ9OTTek9nrmTWk5KGlbsiJ3XUTcAhARL+aevxK4vUAcPbW/THbKvk06qht03D6iK49vK6oYSUcCXwOOjYg3c+0j0px2SNoHGA88mU5NN0qanPqdTgFuS7stBKan5end2k9Jo6+Tgddzp7i1KiUH03u5ClgVERfn2vN9iZ8BukbjFwLTJG0vaRzZ32dpb/GlD5DFwPFp//zfZ2DKHKVq9wfZCNrjZCNL5zU7nhLe3/Vkpyi/I+tHmdHsmEp+v2vJ+pRWpscVqf2zwKOpbQXw6dw+nek//BPA99hyN9LuwN3AGuAuYHhqF9kkoE8ADwOdQy0Hgb8kO9V+KPe3OBq4NsX8EFlxG5Xb57wUw2rSyHNf8ZGNxC5Nf/Mbge0HE7NvATOzyvOpq5lVngudmVWeC52ZVZ4LnZlVngud9auWm/clXZK7qftxSa81IESzPnnU1fol6VDgN2T3YP55Dfv9PXBgRHy5tODMCvARnfUrerh5X9K+kn4qabmkn0vav4ddTyS71s6sqXwLmA3UXODUiFgjaRLwA7IZJwCQtDfZlDz3NCk+s81c6Kxm6WbuvwBuTPNIQjbXWN404KaI+H0jYzPriQudDcRWZNPoHNDHNtOAWY0Jx6xv7qOzmkU2Jc9Tkj4Hm6f//nDX86m/bhjwP00K0exdXOisX5KuJyta+0laJ2kGcBIwQ9IvyW5oz89cO41sRlkP6duQ4MtLzKzyfERnZpXnQmdmledCZ2aV50JnZpXnQmdmledCZ2aV50JnZpX3/zCQUxllOVa/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(10, 10))\n",
    "plt.subplots_adjust(hspace=0.27,wspace=0.5)\n",
    "for col in df.columns:\n",
    "    plt.subplot(5,4,1)\n",
    "    df[y_kepler==0][col].plot.hist(bins=10)\n",
    "    plt.subplot(5,4,2)\n",
    "    df[y_kepler==1][col].plot.hist(bins=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 1.0 min -1.7243757183002422 max 1.7394863019907236\n",
      "std: 0.9999999999999991 min -1.7314290534278698 max 1.6964557176087602\n",
      "std: 1.000000000000001 min -1.7065506204000056 max 1.7079511594477497\n",
      "std: 1.0000000000000013 min -1.719226833085633 max 1.7165703559824166\n",
      "std: 1.0000000000000007 min -1.7346485254319102 max 1.7387575906969763\n",
      "std: 1.0 min -1.7130316108047803 max 1.7293290533469081\n",
      "std: 1.0000000000000018 min -1.752690634466892 max 1.7092715313580786\n",
      "std: 1.000000000000001 min -1.7509822427703123 max 1.7188414562348404\n",
      "std: 0.9999999999999993 min -1.7502522697047167 max 1.7406944228691248\n",
      "std: 0.9999999999999997 min -1.7491709710736287 max 1.7476954407277907\n",
      "std: 0.9999999999999991 min -1.7107809156145881 max 1.7371346371474305\n",
      "std: 0.9999999999999984 min -1.7147511741698986 max 1.7563755645418775\n",
      "std: 1.000000000000002 min -1.7169803056168875 max 1.715020155630479\n",
      "std: 1.0000000000000007 min -1.7437388702093923 max 1.7271470824325654\n",
      "std: 0.9999999999999981 min -1.7050138959835 max 1.7465123023210718\n",
      "std: 1.0000000000000007 min -1.7541049049356034 max 1.6994074797330303\n",
      "std: 0.999999999999998 min -1.7216883106589627 max 1.705755784277664\n",
      "std: 0.9999999999999992 min -1.7195348585751808 max 1.7494266849115834\n",
      "std: 0.9999999999999993 min -1.7378240628008603 max 1.7373485369037516\n",
      "std: 1.0000000000000009 min -1.7309880077335291 max 1.7377975332706759\n"
     ]
    }
   ],
   "source": [
    "nrcols=20\n",
    "col = np.random.random(size=(X2.shape[0],nrcols))\n",
    "scaler = preprocessing.StandardScaler().fit(col)\n",
    "irelevant=scaler.transform(col)\n",
    "for i in range(nrcols):\n",
    "    print('std:',irelevant[:,i].std(),'min',irelevant[:,i].min(),'max',irelevant[:,i].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9380863477682343\n"
     ]
    }
   ],
   "source": [
    "X2_new=np.hstack((X2,irelevant))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "from sklearn.model_selection import cross_val_predict  \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1) \n",
    "cv_scores = cross_val_score(nb.KNeighborsClassifier(n_neighbors=9), X=X2_new, y=y_kepler,cv=cv, scoring='accuracy')  \n",
    "print(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params= {'n_neighbors': 9, 'weights': 'distance'} Accuracy= 0.9380809185347184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "knc = nb.KNeighborsClassifier()\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1) \n",
    "clf = GridSearchCV(knc, param_grid=params,cv=cv,n_jobs=-1,iid='False')  # If cv is integer, by default is Stratifyed \n",
    "clf.fit(X2_new, y_kepler)\n",
    "print(\"Best Params=\",clf.best_params_, \"Accuracy=\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection: Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params= {'n_neighbors': 9, 'weights': 'uniform'} Accuracy= 0.8340623291416074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Select k best features following a given measure. Fit that on whole data set and return only relevant columns \n",
    "X_reduced = SelectKBest(mutual_info_classif, k=2).fit_transform(X2_new, y_kepler)\n",
    "\n",
    "# Let's do now the 10-fold cross-validation again\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1) \n",
    "clf = GridSearchCV(knc, param_grid=params,cv=cv,n_jobs=-1,iid='False')  # If cv is integer, by default is Stratifyed \n",
    "clf.fit(X_reduced, y_kepler)\n",
    "print(\"Best Params=\",clf.best_params_, \"Accuracy=\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params= {'n_neighbors': 11, 'weights': 'distance'} Accuracy= 0.9874248223072717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Select k best features following a given measure. Fit that on whole data set and return only relevant columns \n",
    "X_reduced = SelectKBest(mutual_info_classif, k=13).fit_transform(X2_new, y_kepler)\n",
    "\n",
    "# Let's do now the 10-fold cross-validation again\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1) \n",
    "clf = GridSearchCV(knc, param_grid=params,cv=cv,n_jobs=-1,iid='False')  # If cv is integer, by default is Stratifyed \n",
    "clf.fit(X_reduced, y_kepler)\n",
    "print(\"Best Params=\",clf.best_params_, \"Accuracy=\", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7316, 61)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "original = np.zeros(33)\n",
    "for i in range(33):\n",
    "    X_reduced = SelectKBest(mutual_info_classif, k=i+1).fit_transform(X2_new, y_kepler)\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True) \n",
    "    cv_scores = cross_val_score(nb.KNeighborsClassifier(), X=X_reduced,y=y_kepler, cv=cv, scoring='accuracy')  \n",
    "    original[i]=np.mean(cv_scores)\n",
    "    \n",
    "from matplotlib.pyplot import figure\n",
    "fig = figure(figsize=(12, 6))\n",
    "plt.grid(True)\n",
    "plt.xticks(np.arange(0, 33, step=1))\n",
    "plt.plot(range(1,34),original)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass k=18 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9514670374440284"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = SelectKBest(mutual_info_classif, 18).fit_transform(X2_new, y_kepler)\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1) \n",
    "cv_scores = cross_val_score(nb.KNeighborsClassifier(), X=X_reduced,y=y_kepler, cv=cv, scoring='accuracy')  \n",
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6521406 , -0.58471607, -0.40742565, -0.32118469,  0.32118469,\n",
       "       -0.36849022,  0.36849022, -0.03705655, -0.04901472,  0.03134896,\n",
       "        0.05669936, -0.33309324, -0.33748031, -1.41982675,  1.14135612,\n",
       "       -0.44848702,  0.57507371, -0.2715837 ])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57124725, -0.6521406 , -0.58471607, -0.4314185 , -0.40742565,\n",
       "       -0.25328518,  0.25328518,  0.08623755, -0.32118469,  0.32118469,\n",
       "       -0.18115464, -0.1874685 ,  0.15085127, -0.417555  , -0.36849022,\n",
       "        0.36849022, -0.32992303, -0.02834185,  0.02834185, -0.03705655,\n",
       "       -0.04901472,  0.03134896, -0.40424548, -0.05333417, -0.07315018,\n",
       "        0.05669936, -0.33309324, -0.35729241, -0.33748031, -1.41982675,\n",
       "        1.14135612,  0.37549504, -0.44848702,  0.57507371, -0.1403133 ,\n",
       "       -0.2715837 ,  0.16199256, -0.04406496,  1.2151635 ,  0.7855312 ,\n",
       "        1.48673594, -0.96126626, -0.00570985,  1.08912496,  0.96880079,\n",
       "        0.05536339, -1.48459865, -1.1015224 ,  1.34625968,  1.66457757,\n",
       "        1.17364759, -0.11654567, -0.08150162, -1.25049532, -1.00916462,\n",
       "       -0.73733098, -0.6725327 , -0.16389198, -1.23467638,  1.21866537])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_new[0, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
